{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=20, color='#A020F0'>Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hannah Zanowski<br>\n",
    "10/7/24<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">Learning Goals</span>\n",
    "By the end of this notebook you will\n",
    "1. Become familiar with the basic data structures in xarray and how to create them\n",
    "2. Practice reading in netcdf files and doing computations on xarray datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "[Xarray Documentation](http://xarray.pydata.org/en/stable/)<br>\n",
    "[Xarray API reference](http://xarray.pydata.org/en/stable/api.html)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A little about Xarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray is an extra-glorious library for working with multi-dimensional data that was inspired by Pandas. It uses numpy's N-D arrays, but with _labels_, which makes working with multi-dimensional data much more inuitive and streamlined. It is excellent at handling gridded data, including the [netCDF](https://www.unidata.ucar.edu/software/netcdf/) file format, which is a very common format for atmospheric and oceanic science data. Xarray is one of the packages I use the most in my work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing xarray (and a few others):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DataArrays\n",
    "[DataArray](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html) objects are a core data structure in xarray. There are 4 key elements associated with a DataArray:\n",
    "1. `values`: the numpy array that holds the data\n",
    "2. `dims`: the names for each axis of your data (e.g., 'x','y')\n",
    "3. `coords`: the coordinates that label each data point (e.g., arrays for latitude, dates)\n",
    "4. `attrs`: the attributes of the data (e.g., metadata like units, descriptions of the variables, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an xarray DataArray\n",
    "It's straightforward to make a DataArray. Here's what one looks like in its simplest form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da=xr.DataArray(np.arange(2,22,2))\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this isn't particularly instructive. We need to add arguments for the dimensions, coordinates, and some attributes in order for the values in our DataArray to be meaningful. Let's use our Argo float data from Homework 1 to make a DataArray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the data\n",
    "path='../Homework/data/'\n",
    "argo=np.load(path+'20210901_IndianOcean.npz')\n",
    "list(argo.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the argo temperature data a data array\n",
    "da=xr.DataArray(argo['temperature'],dims=['pressure'],coords={'pressure':argo['pressure']}) #arguments here are data, dimensions, coordinates\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a units attribute to our DataArray. We do that with `.attrs[]`\n",
    "><b><font color='blue'>Note: </font></b> Attributes can be whatever you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.attrs['units']='degC'\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing info from a DataArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the values, coordinates, dimensions,and attributes of your DataArray with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Pandas, there is built-in plotting with xarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.plot(y='pressure',yincrease=False) #pressure increases downward in the ocean, \n",
    "                                      #so tell xarray to plot the y-axis so it is decreasing upward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets\n",
    "[Dataset](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.html) objects are another core data structure in xarray. Like the Pandas Dataframe, an xarray Dataset is just a container for a collection of xarray DataArrays that <b>share coordinates.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an xarray Dataset\n",
    "Let's use our argo data to make our first xarray Dataset. Datasets need, at minimum, the following information:\n",
    "1. `data_vars`: a dictionary `{}` that maps variable names to the data they represent\n",
    "2. `coords`: the coordinates of the data variables<br>\n",
    "\n",
    "As with DataArrays, you can also set attributes with `attrs`. Attributes are techincally not _required_ to create a Dataset (just like for DataArrays), but you should include them! They can be set globally for the dataset and for individual data variables. For some common attributes, check out the [CF Conventions](http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html#_description_of_the_data)\n",
    "\n",
    "><font color='blue'><b>Note:</b></font> The data that you provide in `data_vars` can be DataArrays, pandas objects, etc, or you can create new data as long as it is a tuple of the form `(dims, data[, attrs])`, which xarray will interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an xarray Dataset\n",
    "ds=xr.Dataset(data_vars={'temp':('pressure',argo['temperature'],{'units':'degC'}),\n",
    "                         'salt':('pressure',argo['salinity'],{'units':'PSU'})},\n",
    "             coords={'pressure':('pressure',argo['pressure'])},\n",
    "             attrs={'Description':'Argo salinity and temperature data from the equatorial Indian Ocean'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! But what did we just _do_? Let's unpack the `data_vars` argument in `xr.Dataset()`:<br>\n",
    "\n",
    "As mentioned above, `data_vars` is a dictionary, and it maps the names of variables to the data from those variables. It does this in the form {key:tuple}. For just the variable 'temp' this looks like <br>`{'temp':('pressure',argo['temperature'],{'units':'degC'})}`<br>\n",
    "\n",
    "Here `'temp'` is the dictionary key (the name of the variable) and the tuple contains the pieces of information we are assigning to that variable name. In this case the tuple for `'temp'` contains three pieces of information:\n",
    "1. The dimensions--in this case the only dimension our data has is `'pressure'`\n",
    "><b><font color='red'>Note:</font></b> If your data variable has more than 1 dimension, you will need to provide these as a tuple, e.g. ('dim1','dim2',...)\n",
    "2. The data itself--in this case it's the temperature data from our argo float, `argo['temperature']`\n",
    "3. The attributes of our data variable, which is _another_ dictionary--in this case we only gave the argo temperature data variable a 'units' attribute. Because this is another dictionary, it maps the key (`'units'`) to the value (`'degC'`)\n",
    "\n",
    "The same goes for the `coords` and `attrs` arguments--these are both dictionaries that map a key to a value. In the case of `coords` we have one coordinate, pressure, which is the key, and we map it to the actual pressure values (`argo['pressure']`)\n",
    "\n",
    "><font color='darkmagenta'><b>Reminder:</b></font> If this seems a bit overwhelming, at the end of the day all we're really doing is _labeling_ our data so that it is easier to work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding/dropping data variables\n",
    "You can add data variables to a dataset after you've created it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a data variable for the square of the temperature\n",
    "ds['temp_squared']=ds.temp*ds.temp\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also drop data variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.drop('temp_squared')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using to_dataset() with DataArrays\n",
    "If you have some defined DataArrays, you can use xarray's [to_dataset()](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.to_dataset.html) to create a dataset directly from them. Let's turn our argo temperature DataArray into a DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2=da.to_dataset(name='temp') #because we set up our DataArray nicely, all to_dataset needs is a name for that variable\n",
    "ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working with xarray datasets\n",
    "To show you the real power of xarray, we'll be using [HadISST1](https://www.metoffice.gov.uk/hadobs/hadisst/data/download.html) sea surface temperature data from Jan 2000 to Dec 2020 in the following examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data\n",
    "You can read in [netCDF](https://www.unidata.ucar.edu/software/netcdf/) data using [open_dataset](http://xarray.pydata.org/en/stable/generated/xarray.open_dataset.html) (or [open_mfdataset](http://xarray.pydata.org/en/stable/generated/xarray.open_mfdataset.html) to open multiple files at once!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_dataset('data/HadISST_201501_201912.nc')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of information in this dataset, but how do we interpret it? Let's start by getting the attributes of the data variable `sst`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the attributes are a dictionary, we can also access a specific attribute if we know its name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only the units attribute of SST\n",
    "ds.sst.attrs['units']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Class Question </font>\n",
    "How would you access the `description` attribute for the entire dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing specific data variables is much like in pandas when we access columns, so if we wanted to access data for the sst variable we would just do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['sst']\n",
    "#or\n",
    "#ds.sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting data\n",
    "You can [select data from a Dataset or DataArray using](http://xarray.pydata.org/en/stable/user-guide/indexing.html) `.sel()` or `.isel()`. Like pandas, `.sel()` allows you to select based on coordinate names, etc and `.isel()` allows you to select data based on its integer index (like we have to do with pure numpy arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.sel(time='2015')\n",
    "#or\n",
    "#ds['sst'].sel({'time':'2015'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get SST data at the first time\n",
    "ds.sst.isel(time=0)\n",
    "#or\n",
    "#ds['sst'].isel({'time':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `.sel()` and `.isel()` can take multiple inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose sst data at a specific time and point\n",
    "ds.sst.sel(time='2017-02',latitude=10.5,longitude=160.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you don't remember or know the _exact_ coordinate values? You can set the `method` keyword argument!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.sel(time='2017-02',latitude=10,longitude=160.5,method='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing\n",
    "If you want to select a range of data you need to use xarray's `slice()` argument. Let's use slice to select a subset of data for our entire dataset. In this case we'll subset the data so that it spans 30.5˚E-179.5˚E and 45˚N to 90˚N:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_slice=ds.sel(time=slice('2015-01-16','2016-12-16'),longitude=slice(30.5,179.5),latitude=slice(45,None))\n",
    "#or\n",
    "#ds_slice=ds.sel({'time':slice('2015-01-16','2016-12-16'),'longitude':slice(30.5,179.5),'latitude':slice(45,None)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a quick 2D plot of SST using the first date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_slice.sst.sel(time='2015-01').plot()\n",
    "plt.gca().set_facecolor('0.7') #hack for filling in the land\n",
    "\n",
    "#This is equivalent to\n",
    "#ds_slice.sst.isel(time=0).plot()\n",
    "#ds.slice.sst.sel(time='2015-01-16').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, this isn't quite what we wanted...\n",
    "\n",
    "><b><font color='red'>First</font></b>, we aren't in the right region--we're looking at Australia although we sliced our data to be in the Northern Hemisphere.<br>\n",
    "><b><font color='red'>Second</font></b>, the range of SSTs is wildly unphysical. \n",
    "\n",
    "Let's deal with the slicing issue first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the latitudes of the dataset\n",
    "ds_slice.latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look closely at the dataset output, you'll see that this is because of the order that our latitude values are provided in the dataset--they go from 90N to 90S, _not_ 90S to 90N! We can fix this a couple of different ways:\n",
    "\n",
    ">1. We can change the slice argument for latitude slightly: `slice(None,45)`\n",
    ">2. We can just reset the latitude coordinate for the entire dataset\n",
    "\n",
    "Let's use option 2 so we don't have to deal with it again. Here we'll be using [reindex()](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.reindex.html) to reindex the dataset based on our new latitude coordinate that starts at -89.5 and ends at 89.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.reindex(latitude=list(reversed(ds.latitude))) #use reversed to reverse the original latitude list\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering with where()\n",
    "Now let's deal with the second problem, which is the enormous and unphysical range of SST values. This weird range is because this dataset has some missing values under sea ice, and these are set to -1000. Let's get rid of those using xarray's [where()](http://xarray.pydata.org/en/stable/generated/xarray.where.html) function. \n",
    "\n",
    "><font color='red'><b>Note: </b></font>`where()` takes as input a condition on your data and replaces the values that <font color='red'><b>_DO NOT_</b></font> meet that condition with nan. If you want those values to be replaced with a value other than nan, use the `other` keyword argument.\n",
    "\n",
    "Before we use `where()` to get rid of the missing values, we want to make a mask for land, which is currently set as nan. If we don't keep track of the land separately, then once we use `where()` both the missing values and land values will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land=np.isnan(ds.sst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a quick plot with matplotlib's pcolormesh\n",
    "plt.pcolormesh(land)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our land mask let's use `.where()` to turn the missing values into nan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.where(ds.sst>-1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add our land mask to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['land']=land\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's make another plot, but now using our SSTs without the missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "#add land first\n",
    "ax.pcolormesh(ds.land,cmap=plt.cm.gray_r)\n",
    "#then plot over the land with SSTs\n",
    "cs=ax.pcolormesh(ds['sst'].sel(time='2015-01-16').squeeze(),cmap=plt.cm.plasma)\n",
    "cbar=plt.colorbar(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><font color='blue'><b>Note:</b></font> In this particular case, if all you wanted to do was plot the data and _not_ bother with `where()` you could just do the following once you read in your data:\n",
    "\n",
    "```bash\n",
    "cmap=plt.cm.plasma.copy()\n",
    "cmap.set_under('0.5') #set values under the minimum value to be gray\n",
    "fig,ax=plt.subplots()\n",
    "#plot the SSTs, but set the min and max values for the colorbar\n",
    "cs=ax.pcolormesh(ds['sst'].sel(time='2015-01-16').squeeze(),cmap=cmap,vmin=-2, vmax=ds.sst.max())\n",
    "cbar=plt.colorbar(cs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using where() for multiple conditions\n",
    "If you want to filter your data based on multiple conditions at once, you can chain several `where()` functions together, or you can use logical operators within `where()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only the SST values that fall between 5˚C and 20˚C that are south of the Equator\n",
    "sst_subset=ds.sst.where(ds.sst>=5.0).where(ds.sst<=20.0).where(ds.latitude<0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot your SST subset at a single time\n",
    "plt.gca().pcolormesh(ds.longitude,ds.latitude, ds.land,cmap=plt.cm.gray_r) #hack for adding land so we know where we are\n",
    "sst_subset.sel(time='2019-01').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#or do the same thing with all of the commands together\n",
    "#Note: the syntax must be exactly as is here otherwise you will get an error!\n",
    "sst_subset=ds.sst.where((ds.sst>=5.0) & (ds.sst<=20.0) & (ds.latitude<0.0))\n",
    "\n",
    "#plot again\n",
    "plt.gca().pcolormesh(ds.longitude,ds.latitude, ds.land,cmap=plt.cm.gray_r) #hack for adding land so we know where we are\n",
    "sst_subset.sel(time='2019-01').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing computations on xarray Datasets and DataArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you do computations on xarray objects, the coordinates are preserved. You can apply most numpy functions to Datasets and Datarrays. Like Pandas though, not every function from a package is designed to work with xarray objects. You can still apply these functions to your xarray data, but the output will not be an xarray DataArray or Dataset unless you use [apply_ufunc](http://xarray.pydata.org/en/stable/generated/xarray.apply_ufunc.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_mn=ds.sst.mean(dim='time') #you can supply dimension names instead of numerical axes indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick plot with built-in xarray plotting\n",
    "sst_mn.plot()\n",
    "plt.gca().set_facecolor('0.7') #make the plot background light gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you supply more than one dimension at a time, it needs to be a tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the zonal mean, time mean SSTs\n",
    "sst_zn_mn=ds.sst.mean(dim=('time','longitude'))\n",
    "sst_zn_mn.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot SST anomalies at a point in the equatorial Pacific Ocean\n",
    "sst_pac=ds.sst.sel(latitude=0.5,longitude=-150.5)\n",
    "sst_anom=sst_pac-sst_pac.mean()\n",
    "sst_anom.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting no more!\n",
    "Because our data is labeled, xarray can handle broadcasting internally. The hell that is broadcasting with numpy arrays is not a problem in xarray! Below we'll print the shapes of the longitude coordinate and the sst data from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.longitude.shape)\n",
    "print(ds.sst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a contrived example (i.e., one that you'll probably not find yourself needing to do), let's multiply the 3D SST data by the 1D longitude. If we were using standard numpy arrays we'd have to do some broadcasting/tiling first before we could multiply these two arrays together, but <b>this is _NOT_ the case with xarray labeled data!</b> All you have to do is multiply them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_times_lon=ds.sst*ds.longitude\n",
    "sst_times_lon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data at one time\n",
    "sst_times_lon.sel(time='2016-09').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby\n",
    "[Groupby](http://xarray.pydata.org/en/stable/user-guide/groupby.html) also exists in xarray, and it works much the same way it does in pandas. You can do many computations with groupby, and you'll get a chance to practice with it more in your homework. Here are some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example 1</b>: Compute the mean SST for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_ann_mn=ds.sst.groupby('time.year').mean('time')\n",
    "sst_ann_mn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example 2</b>: Compute seasonal mean SSTs\n",
    "\n",
    "><b><u><font color='red' size=3.5>CAUTION:</font></u> when grouping by `time.season` xarray is NOT smart enough to know to group December of the previous year with January and February of the current year. Instead it will group December, January, and February of the same year!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_seasonal_mn=ds.sst.groupby('time.season').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the dimensions of seasonal mean SSTs\n",
    "sst_seasonal_mn.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access the contents of the 'season' dimension\n",
    "sst_seasonal_mn.season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the difference between (Southern Hemisphere) spring and fall SSTs\n",
    "plt.gca().set_facecolor('0.7')\n",
    "cs=plt.contourf(ds.longitude, ds.latitude,sst_seasonal_mn.sel(season='SON')-sst_seasonal_mn.sel(season='MAM'),\n",
    "                  cmap=plt.cm.RdBu_r,levels=np.arange(-10,11,1),extend='both')\n",
    "plt.colorbar()\n",
    "plt.title('SH Spring (SON) - Fall (MAM) SSTs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><b><u>Dealing with DJF properly</u></b></font><br>\n",
    "The below code is a workaround for grouping the correct December with the correct January and February for winter. The code isolates DJF with `where()` and uses a rolling mean to compute the seasonal mean for DJF. As a result Jan and Feb of the 1st year of data and Dec of the last year of data are excluded, but this is fine as these do not have complete information for a full DJF mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_djf=ds.sst.where(ds['time.season']=='DJF')\n",
    "sst_djf=sst_djf.rolling(min_periods=3,center=True,time=3).mean()\n",
    "sst_djf=sst_djf.mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of how this can impact our plots, let's compare two time series for the correct vs incorrect way of computing DJF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The incorrect way\n",
    "lat=-40\n",
    "lon=50\n",
    "sst_seasonal=ds.sst.sel(latitude=lat,longitude=lon,method='nearest').sel(time=ds.time.dt.season=='DJF')\n",
    "sst_djf_v1=sst_seasonal.groupby(sst_seasonal.time.dt.year).mean('time')\n",
    "\n",
    "#The correct way\n",
    "#We have to do a few extra/different steps to group the correct Decembers with the correct Jans and Febs\n",
    "sst_djf_v2=ds.sst.sel(latitude=lat,longitude=lon,method='nearest').rolling(min_periods=3,center=True,time=3).mean()\n",
    "#min_periods=2 would let us keep the first J-F mean as a data pt for 2015, which is reasonably ok \n",
    "#even if we don't have Dec 2014\n",
    "sst_djf_v2=sst_djf_v2.sel(time=sst_djf_v2.time.dt.month==1) #Choose only the rolling means centered on January\n",
    "#to get the correct DJF sequence because the time window is 3\n",
    "\n",
    "plt.plot(sst_djf_v1,label='Incorrect',color='k')\n",
    "plt.plot(sst_djf_v2,label='Correct',color='g')\n",
    "plt.gca().set_xlim((0,4))\n",
    "plt.gca().set_xticks(np.arange(0,5))\n",
    "plt.gca().set_xticklabels(np.arange(2015,2020))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving your data\n",
    "You can [save your xarray Datasets in many formats](http://xarray.pydata.org/en/stable/user-guide/io.html), including netcdf. To save your Dataset to a netcdf file, use [to_netcdf](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_netcdf.html). For practice, let's save one year of SSTs to a netcdf file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_save=ds.sel(time=slice('2015-01','2015-12'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_save.to_netcdf('HadSST_201501-201512.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try opening your saved dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2=xr.open_dataset('HadSST_201501-201512.nc')\n",
    "ds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:uw-fall-2024]",
   "language": "python",
   "name": "conda-env-uw-fall-2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

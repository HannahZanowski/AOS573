{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=20, color='#A020F0'>Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hannah Zanowski<br>\n",
    "10/3/22<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">Learning Goals</span>\n",
    "By the end of this notebook you will\n",
    "1. Become familiar with the basic data structures in Pandas and how to create them\n",
    "2. Practice reading in data and doing computations on dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources\n",
    "[Pandas website](https://pandas.pydata.org/)<br>\n",
    "[Pandas Documentation](https://pandas.pydata.org/docs/)<br>\n",
    "[Pandas API reference](https://pandas.pydata.org/docs/reference/index.html#)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A little about pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a glorious library for working with tabular data. It relies on high-level data structures and comes with a huge set of useful analysis tools, including easily reading in .txt and .csv files. Pandas uses label-based indexing that makes working with data much more streamlined and easier to understand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by importing pandas (and a few of our other favorites):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a pandas series\n",
    "[Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html) objects are a core data structure in pandas. A series is much like a 1D numpy ndarray, except that there is a labeled index associated with the values in the series. Like all things python, there are many ways to [create a pandas series](https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pandas series from scratch\n",
    "animal_counts=pd.Series(data=[10,8,22,1,17,6,3,0], \n",
    "                      index=['Dog','Cat','Bird','Alligator',\n",
    "                             'Giraffe','Lion','Bear','Penguin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing the data\n",
    "You can access series data by using `.loc[]` or `.iloc[]`. The first allows you to retrieve a value based on the named index, and the second allows you to retrieve a value based on an integer index (like we use in numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_counts.loc['Cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_counts.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access only the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_counts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to access only the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_counts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing computations\n",
    "You can apply most numpy functions to pandas series without any issue. The best part is that your index will be preserved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(animal_counts-np.mean(animal_counts))/np.std(animal_counts,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating a pandas dataframe\n",
    "[DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas-dataframe) objects are another core data structure in pandas. A dataframe is basically a 2D container for a collection of series with the same index. You can do computations across the columns of a dataframe, and you can think of it like a spreadsheet or any other table of data. Like series, there are many ways to [create a pandas dataframe](https://pandas.pydata.org/docs/user_guide/dsintro.html#dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's create a pandas dataframe using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = {'quarter':[1,3,4],\n",
    "        'year':[2015,2014,2019],\n",
    "        'enrollment':[200,np.nan,85],\n",
    "        'prev_enrollment':[150,10,102]}\n",
    "df = pd.DataFrame(class_data, index=['AOS100', 'AOS742', 'AOS384'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can extract summary information about a pandas dataframe with `.info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also extract summary statistics from a dataframe with `.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Accessing data in a pandas dataframe\n",
    "You can access data in a dataframe with index labels or index numbers like we used before, and you can access entire columns with column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['AOS100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['enrollment']\n",
    "#or df.enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access more than one column or row:\n",
    "df[['quarter','enrollment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering based on boolean operators\n",
    "You can filter your datasets based on conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.prev_enrollment>50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering with .where()\n",
    "Pandas' [where()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html) is another really useful tool for filtering, but <b><font color='red'>NOTE:</font></b> It only works when all of the columns are the same datatype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df.quarter<2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Creating new columns, merging data, and reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column in our dataframe\n",
    "df['enrollment_change'] = (df.enrollment-df.prev_enrollment)/df.prev_enrollment\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column separately and merge into our dataframe\n",
    "instructor=pd.Series(['Rick', 'Morty', None ],\n",
    "                     index=['AOS100', 'AOS742', 'AOS384'],\n",
    "                     name='instructor')\n",
    "# returns a new DataFrame\n",
    "df=df.join(instructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add another index (in our case another class) to the dataframe\n",
    "df=df.reindex(index=['AOS100', 'AOS742', 'AOS384', 'AOS121'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Setting data in a dataframe\n",
    "You can use [at[]](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.at.html) or [iat[]](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iat.html) to set values in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign data to some of the columns\n",
    "df.at['AOS121','quarter']=2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set data in place using conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a subset of the dataframe to work on for this example\n",
    "df_new=df.drop(columns='instructor')\n",
    "\n",
    "#Make a condition based on enrollment\n",
    "df_new[df_new.enrollment>50]=-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Reading in data\n",
    "Pandas can [read in all sorts](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) of tabular data (csv, excel, even stuff from your local clipboard!!). Let's use pandas to read in our Niño3.4 data from the first in-class notebook. If you don't remember where it is just go ahead and download it again:\n",
    "\n",
    "```bash\n",
    "!curl -O https://www.cpc.ncep.noaa.gov/products/analysis_monitoring/ensostuff/detrend.nino34.ascii.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34=pd.read_csv('detrend.nino34.ascii.txt',sep='\\s+')\n",
    "df_n34.head() #default is to show only 5 rows; you can change this by providing a different argument to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34.iloc[856]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case we didn't set an index (so it's just a number), but we could set whatever index we want, including one of the data columns. Let's create our own index called 'date' using pandas' [to_datetime()](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html) function. `to_datetime()` can make datetime objects out of columns of a pandas dataframe, but the columns need to be named 'year', 'month' etc for pandas to be able to recognize them as years and months. So let's rename our 'YR' and 'MON' dataframe columns to reflect this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34=df_n34.rename(columns={'YR':'year','MON':'month'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new datetime index and use the date as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the new index\n",
    "new_index=pd.to_datetime(df_n34[['year', 'month']].assign(days=np.ones(len(df_n34.ANOM.values))))\n",
    "new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the index to be new_index\n",
    "df_n34=df_n34.set_index(new_index)\n",
    "df_n34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access values by the date index that we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34.loc['1997']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aren't going to use the TOTAL and ClimAdjust columns here, so let's get rid of them using [drop()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34=df_n34.drop(columns=['TOTAL','ClimAdjust'])\n",
    "df_n34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Doing computations on your dataframe\n",
    "Let's revisit some of what we did in the first in-class notebook to (hopefully) show you how doing computations in pandas is much more intuitive than using unlabeled numpy arrays!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get the start and end dates of df_n34:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print start and end dates of the dataframe\n",
    "print(df_n34.index[0])\n",
    "print(df_n34.index[-1])\n",
    "\n",
    "#or \n",
    "#df_n34.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the subset of Niño3.4 SST anomaly data that covers the same date range as the SOI data\n",
    "df_n34.loc['1951-01':'2021-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting\n",
    "You can count the number of non-nan elements in the columns of a DataFrame with [count()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html) and you can retrieve counts of unique items in a pandas Series with [value_counts()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34.count() #apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34.month.value_counts() #applies to a Series object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' [groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) functionality is also really powerful. It allows you to group data based on a condition that you provide. You can then do computations on the resulting groups. A common use of groupby is grouping by time like we'll do below, but you can use groupby in many other ways as well, as long as it makes sense for your data!\n",
    "\n",
    "As an example, we'll use `groupby()` to create a monthly climatology for our Niño3.4 SST anomalies from Jan 2000 to Dec 2021:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the dates we want:\n",
    "n34_2000_2021=df_n34.ANOM.loc['2000-01':'2021-12']\n",
    "\n",
    "#Then use groupby to group the same months together, and then take the mean over all of the years\n",
    "n34_climo=n34_2000_2021.groupby(n34_2000_2021.index.month).mean('year')\n",
    "\n",
    "n34_climo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resampling\n",
    "\n",
    "Pandas' [resample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html) function is useful for resampling time series. <b>For it to work properly, your dataframe must have a datetime-like index!</b>\n",
    "\n",
    "For this example, we'll downsample the Niño3.4 SST anomalies from monthly output to annual output (note that in this case you could just use groupby to get the same result):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n34_ann=df_n34.ANOM.resample('AS').mean() #'AS' means annual\n",
    "n34_ann.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Plotting data\n",
    "Pandas has a number of basic [built-in plotting options](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html) for visualizing your data. You can also plot pandas data using matplotlib, etc.\n",
    "\n",
    "Let's start by plotting the Niño3.4 SST anomalies using built-in plotting commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Niño3.4 SST anomalies using built-in plotting\n",
    "df_n34['ANOM'].plot(title='Niño3.4 SST anomalies',xlabel='Time (years)',ylabel='SST anomaly ($\\degree$C)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the anomalies using matplotlib. Notice how we don't need to create our own time axis like we had to in the first notebook wwhen we were using raw numpy arrays! This is because we created a `DatetimeIndex` for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Niño3.4 SST anomalies using matplotlib\n",
    "fig,ax=plt.subplots()\n",
    "fig.set_size_inches(10,3)\n",
    "ax.plot(df_n34['ANOM'],color='0.5',lw=1)\n",
    "plt.title('Niño3.4 SST anomalies')\n",
    "plt.xlabel('Time (years)')\n",
    "plt.ylabel('SST anomaly ($\\degree$C)');\n",
    "ax.set_xlim([datetime.date(1950,1,1),datetime.date(2020,1,1)])\n",
    "\n",
    "#plot the resampled data as well\n",
    "plt.plot(n34_ann,color='k',lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a histogram of the monthly Niño3.4 SST anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n34.ANOM.hist(bins=np.arange(-2.25,2.26,0.5),color='navy',ec='goldenrod',grid=False);\n",
    "#bins here are the bin edges!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

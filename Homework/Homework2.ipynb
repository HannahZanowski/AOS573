{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=20, color='#A020F0'>Homework 2</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this homework you'll further explore scipy and pandas. For the pandas problems you'll be working with oceanographic research cruise data from the Arctic\n",
    "\n",
    "<b><font color='red'>Due Date: 9 October 2023</font></b><br>(by the beginning of class)\n",
    "\n",
    "<b>How you will turn in this assignment</b><br> When you are ready to turn in your homework, do the following steps:\n",
    "1. Execute all cells in your notebook so that the results are visible, and save one more time. It is ok if you have code that you practiced with, but <b><u>make sure your final answers to each question are clearly marked so that your TA and I know what to grade</u></b>. (You can also collapse the code and outputs that you _don't_ want us to grade; options to collapse and expand code are in the 'View' menu in the upper left)\n",
    "2. Open a terminal and navigate to your local `aos573_completed_assignments` repository and make a new directory called `completed_HW2`\n",
    "3. Move or copy your completed jupyter notebook into this directory\n",
    "4. `add` and `commit` the `completed_HW2` directory and its contents to your local `aos573_completed_assignments` repository\n",
    "5. Finally, `push` your changes to your remote `aos573_completed_assignments` repository: `git push finished_work main` (you'll need to enter your username and personal access token)\n",
    "6. <b><font color='red'>REMINDER: DO NOT TRACK OR PUSH THE DATA USED IN THE NOTEBOOK</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Working with Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Numerically integrating the Lorenz Equations\n",
    "\n",
    "The [Lorenz Equations](https://en.wikipedia.org/wiki/Lorenz_system) were developed by [Ed Lorenz](https://en.wikipedia.org/wiki/Edward_Norton_Lorenz) in the 1960s. They describe the chaotic motion of the atmosphere in very simplified terms (you can access his actual paper [here](https://journals.ametsoc.org/view/journals/atsc/20/2/1520-0469_1963_020_0130_dnf_2_0_co_2.xml)). The equations are as follows:\n",
    "\n",
    "<center>\n",
    "$\\dot x=\\sigma(y-x)$<br>\n",
    "$\\dot y=rx-y-xz$<br>\n",
    "$\\dot z=xy-bz$<br>\n",
    "</center><br>\n",
    "\n",
    "Where $\\sigma$, $r$, and $b$ are tunable parameters ($\\sigma$ is the Prandtl number and $r$ is the Rayleigh number if you want to know).\n",
    "\n",
    "The goal of this problem is to use Scipy's 4th/5th order Runge-Kutta algorithm via [solve_ivp()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html) to solve the above system of equations (for now with $\\sigma$=$r$=$b$=1) and the following initial conditions:\n",
    "\n",
    "<center>\n",
    "$x(t=0)=0$<br>\n",
    "$y(t=0)=1$<br>\n",
    "$z(t=0)=0$<br>\n",
    "</center><br>\n",
    "\n",
    "You'll work through it in several steps below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1.1 Define a function\n",
    "Create a function that takes the following as arguments and _returns_ the values for $\\dot x$, $\\dot y$, $\\dot z$ at a particular timestep:\n",
    "1. A time interval of the form `[time1, time2]`\n",
    "2. A 1D array of the three values for the initial conditions `[x(0),y(0),z(0)]`\n",
    "3. Values for $\\sigma$, $r$, and $b$ (the default can be 1 for now)\n",
    "\n",
    "This might sound confusing, but all I am asking you to do is take the above equations and put them inside a function. Within your function you will need to make sure that x, y, and z are set to the initial conditions that you provide as arguments to the function. Your function body (excluding the return statement) should thus have something like 4 lines: 1 line for setting the initial conditions and another 3 for calculating $\\dot x$, $\\dot y$, $\\dot z$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1.2 Solve your set of equations\n",
    "Use [solve_ivp()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html) to solve the equations. As arguments to solve_ivp, you'll need to provide the function you created, the inputs (arguments) to your function, the integration method (Runge Kutta 4/5), and the timesteps (the evaluation period). Use 10000 timesteps over the time interval `[0,100]` to create your timesteps. <b>Please read the solve_ivp documentation carefully!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1.3 Plot your results but with new parameters\n",
    "Now that you have a working solver, change the values of $\\sigma$, $r$, and $b$ so that your solutions give you the classic Lorenz Attractor. Make a plot of your solutions (specifically the solution for $x(t)$ vs the solution for $z(t)$). Give your plot a title and x and y axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Making an fft of an audio recording of your voice\n",
    "\n",
    "1. Use this [voice recording website](https://virtualspeech.com/tools/voice-recorder) to make a recording of yourself reading the following passage from _To Kill a Mockingbird_. Do your best to read the passage aloud at your normal conversation volume and pace (don't worry too much about this part though).\n",
    "<blockquote>“Atticus said to Jem one day, “I’d rather you shot at tin cans in the backyard, but I know you’ll go after birds. Shoot all the blue jays you want, if you can hit ‘em, but remember it’s a sin to kill a mockingbird.” That was the only time I ever heard Atticus say it was a sin to do something, and I asked Miss Maudie about it. “Your father’s right,” she said. “Mockingbirds don’t do one thing except make music for us to enjoy. They don’t eat up people’s gardens, don’t nest in corn cribs, they don’t do one thing but sing their hearts out for us. That’s why it’s a sin to kill a mockingbird.”</blockquote> \n",
    "\n",
    "2. When you are done recording, choose the `download (M4A)` option, and then use [this audio coverter](https://virtualspeech.com/tools/audio-converter) to convert your recording to a `.wav` file. Once you have converted it, upload it to the class jupyterhub so you can load it in your notebook (<font color='red'>you do not need to turn in your .wav file when you turn in your homework!</font>) \n",
    "3. Read in your `.wav` file using [scipy.io.wavfile.read](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html) (make sure you read what the outputs of this are!) and look at your data (i.e, what is in your wavfile that you read in? What are the dimensions of the different pieces of data and what do they represent?) I don't need you to write the answers to these questions in your notebook, but they are there to help you understand what it is from the file that you need to use for the next step.\n",
    "4. Compute the fft of your voice recording using scipy.fft.fft\n",
    "5. Plot your results, <b>save them as a `.png` file with your last name in the file name</b>, and drop them in this [google drive folder](https://drive.google.com/drive/folders/1etyRjifV0sZDKTLFzsf7XaJlGlOW4FbW?usp=sharing) so we can compare them! <u>You must turn in your final plot in the google drive to get full points for this question.</u>\n",
    "\n",
    "<b><font color='red'>For steps 3-5 please make sure you add comments to your code!</font></b>\n",
    "\n",
    "In order to make our plots comparable, please ensure that your plot adheres to the following parameters:\n",
    "1. Make sure the figure size is 12x4\n",
    "2. Set your plot xlim to go from 0 to 1000\n",
    "3. Scale your amplitudes by the maximum amplitude in your fft (just divide by the maximum value so that your y-values span [0,1])\n",
    "4. Add a title (it should say something like 'fft of [your name]'s voice recording')\n",
    "5. Add x and y axis labels (the x-axis unit is Hz)\n",
    "6. Set the default linewidth to be 0.5 and change the line color (you can pick whatever color you want)\n",
    "7. Add text on your plot that denotes the frequencies of the two largest peaks (the text should simply state the frequency of the peak and appear next to the peak\n",
    "><b><font color='green'>Hint</font></b>: take a look at [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) and [annotate](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.annotate.html)\n",
    "\n",
    "Here is an example of what the end result should look like using a recording of my and Ángel's voices (your plot will, of course, only have one panel containing the fft of your voice):\n",
    "\n",
    "<img src='Images/HA_voice_ffts.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3 Troubleshooting Errors\n",
    "Imagine a friend of yours has been tasked with writing some code to compute a [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) for two variables that are generated by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for generating the variables\n",
    "x=np.linspace(-1,1,100) #create 100 values on the interval [-1,1]\n",
    "#parabola for variable y1\n",
    "y1=x**2\n",
    "#quartic + noise for variable y1\n",
    "y2=x**4+np.random.randn(100) #random.randn adds random noise\n",
    "##!!!NOTE: the values for y2 will not stay the same if you run this block again and that's ok!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your friend has written some additional code below to compute the Pearson correlation coefficient $r_{xy}$ for two variables $x$ and $y$ as defined by his textbook:<br>\n",
    "<center>$\\large r_{xy}={\\frac {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})(y_{i}-{\\bar {y}})}{{\\sqrt {\\sum _{i=1}^{n}(x_{i}-{\\bar {x}})^{2}}}{\\sqrt {\\sum _{i=1}^{n}(y_{i}-{\\bar {y}})^{2}}}}}$</center><br>\n",
    "\n",
    "where $\\bar{x}$ and $\\bar{y}$ are the means of the respective variables and $x_{i}$ and $y_{i}$ are individual values. \n",
    "\n",
    "He tells you that his code is not working and he isn't sure how to fix it. Being the awesome friend you are, you take a look at his code and correct several syntax and other general computational errors that he missed. \n",
    "\n",
    "<b>For this problem you need to do the following:</b>\n",
    "1. List each of the errors that you find in your friend's code. It will help to run the code below and to try using the function to compute the correlation between y1 and y2. \n",
    "2. Correct the errors and show that the defined function actually works the way you'd expect by testing it on y1 and y2 above and comparing the result to that of `scipy.stats.pearsonr`\n",
    "> <b>Note:</b> In the code below the result is rounded to 2 decimal places, so that's all the accuracy I am looking for in the correlation coefficient comparison\n",
    "3. Using only numpy and/or scipy, re-write the corrected code in 3 lines. <b>This means you should be able to condense the entire code in the body of the function into one line. </b>Make sure that your final code provides the correct result by comparing it to `scipy.stats.pearsonr` as in 2). You can use whatever built-in numpy and scipy functions that you want, <font color='red'><b>as long as you do not use scipy.stats.pearsonr :)</b></font>. To get full points for this problem, the above code should be condensed in a meaningful way--that means it should be more straightforward than what is provided below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR FRIEND'S CODE\n",
    "def rcorr(x1,x2):\n",
    "    #Compute expectation and variance for first variable\n",
    "    x1bar=np.sum(x1/len(x1)\n",
    "    xvar=np.sum((x1-x1bar)^2)\n",
    "    #Compute expecation and variance for second variable\n",
    "    x2bar=np.sum(x1)/len(x2)\n",
    "    x2var=np.sum((x2-x2bar)^2)\n",
    "    #Compute pearson r correlation coefficent\n",
    "    r=np.sum((x1-x1bar)*(x2-x2bar))/np.sqrt(x1var)*np.sqrt(x2var)\n",
    "    r=np.round(r,2)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CORRECTED CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR SHORTENED VERSION OF THE CORRECT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Working with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data and summarizing it\n",
    "The data we'll be using for this part of the homework is from the [Global Ocean Data Analysis Project (GLODAP)](https://www.glodap.info/), which is a massive, global synthesis of quality-controlled ocean biogeochemical observations. GLODAP contains data from thousands of cruises from the early 1970s to the present. Here we'll only work with data from the Arctic Ocean.\n",
    "\n",
    "Run the following commands to download the GLODAP Arctic Ocean data:\n",
    "```bash\n",
    "!curl -O https://www.ncei.noaa.gov/data/oceans/ncei/ocads/data/0237935/GLODAPv2.2021_Arctic_Ocean.csv \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has far more variables than you'll be working with in this assignment, so to help you out, below I've given you the code to read in only a subset of the variables, and I've renamed the columns slightly. If you want to compare what I've done here to the unsubsetted dataset, feel free to read the entire thing in on your own with `pandas.read_csv()`. In my code below `pd` is what I called pandas when I imported it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of variables \n",
    "names=['station','year','month','day','hour','minute','latitude','longitude','depth','theta','salinity',\n",
    "                      'salinityf','sigma0','oxygen','oxygenf','cfc11','cfc11f']\n",
    "#Read in only the variables above with `usecols`\n",
    "df=pd.read_csv('GLODAPv2.2021_Arctic_Ocean.csv',sep=',',usecols=['G2'+i for i in names])\n",
    "#Reset the column names to be those in the list above and not the original names, \n",
    "#which all have 'G2' appended to the front\n",
    "df.columns=names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dataset info that you will find helpful (or access the entirety of the [metadata](https://www.ncei.noaa.gov/data/oceans/ncei/ocads/metadata/0237935.html) if you would like):\n",
    "\n",
    "1. year, month, day, hour, minute = sampling date and time\n",
    "2. latitude/longitude = geographical coordinates of the sampling location\n",
    "3. depth (m) = the depth of the water sample in meters\n",
    "4. missing fill value = -9999.0 (the fill value used when data is missing)\n",
    "\n",
    "Here is a list of the remaining variables, their descriptions, and their units:\n",
    "\n",
    "| Variable | Description | Unit | \n",
    "| - | - | - |\n",
    "| theta | potential temperature | $^\\circ$C |\n",
    "| salinity | salinity on the practical salinity scale | none |\n",
    "| salinityf | salinity flag; 0 = interpolated, 2 = good data, 9 = missing data | none |\n",
    "| sigma0 | potential density referenced to the ocean surface | kg m$^{-3}$ |\n",
    "| oxygen | oxygen content | $\\mu$mol kg$^{-1}$ |\n",
    "| oxygenf | oxygen flag; 0 = interpolated, 2 = good data, 9 = missing data | none |\n",
    "| cfc-11 | chlorofluorcarbon-11 content | pmol kg$^{-1}$ |\n",
    "| cfc-11f | cfc-11 flag; 2 = good data, 9 = missing data | none |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Get some basic information about your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1.1 Print the summary information for your dataframe\n",
    "1. How many samples are there for any given variable?\n",
    "2. How many different datatypes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1.2 Print the summary statistics for your dataframe\n",
    "1. What is the range of latitude and longitude that the dataset covers?\n",
    "2. What is the mean potential temperature? Does this seem reasonable? What do you think is the cause?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Replacing missing values\n",
    "Use [where()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html) to replace all of the missing values with NaNs. Rerun your summary statistics from Q2.1.2. What is the mean potential temperature now? For this question, please print _only_ the new mean value of potential temperature, and not the entire summary statistics table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 A quick look at the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.3.1 Show the last 8 values of the dataset. \n",
    "This is the data collected at one stop (a 'station') on one reasearch cruise. You can tell this because the lat/lon values don't change, nor does the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.3.2 For which variables were data not collected at this station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.3.3 Over what depth range were water samples collected at this station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1 Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.1.1 Make a very quick line plot of the years in the dataset\n",
    "Use pandas built-in plotting and don't bother making any adjustments to the output. What does the plot tell you about how the years are arranged in your dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.1.2 Sort your dataframe so that the years are increasing\n",
    "Use your sorted dataframe for the rest of the assigment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.2.1 How many samples were taken above and below 500 m?\n",
    "Base your answer off of depth, not one of the other variables like salinity, etc, as some of those will have missing values. Include samples at depths exactly at 500 m in the 'above 500 m' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.2.2 How many salinity, oxygen, and CFC-11 samples in the entire dataset were interpolated?\n",
    "Provide your answers as percentages of the total number of samples for each variable. Exclude missing values when computing the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.2.3 Between 1980 and 1990, how many oxygen samples were taken north of 80˚N?\n",
    "Include samples at exactly 80˚N in your counts, but exclude any samples taken in the year 1990. Do not include missing values in your counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.2.4 How many distinct locations in the Arctic were sampled?\n",
    "In this question, I want you to find the total number of _unique_ lat/lon _pairs_. \n",
    "><b><font color='green'>Hint:</font></b> Take a look at [drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.2.5 In what years were the largest and smallest number of samples taken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.2.6 In how many years were data collected?\n",
    "How does this compare to the total number of years that the dataset spans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 Make a histogram of the number of samples in each month \n",
    "For this problem, you'll need to create a new dataframe using `drop_duplicates()`.  Because the number of sample depths varies per station, if we make a histogram based solely on the 'months' column, we'll skew our results based on the number of depths sampled at a given station. To avoid counting mulitple samples across depth at the same station, what we truly want is the unique _date_ and _time_ that sampling occurred at a particular station, so you should make your histogram based on your new dataframe that ignores duplicate entries for the date and time.\n",
    "\n",
    "No need to bother making your plot look pretty for this question--as long as you can answer the questions below then it's fine (but do make sure that your plot has one bin per month)!\n",
    "\n",
    "1. In what month were the largest number of samples taken?\n",
    "2. In what month were the smallest number of samples taken?\n",
    "3. Pretend like the data you plotted on your histogram is the data you have for one year. If you took the annual mean of your data, how might you expect your results to be biased (i.e. toward what season would your annual mean skew)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.4 Visualizing data with a box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.4.1 Make a box plot of the spread in number of samples across all months for each year\n",
    "Use your new dataframe from Q3.3. Your [box plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html) should have one box showing the spread in monthly sample numbers for each year. Your x-axis should be the years of the dataset and your y-axis should be the months (these should be numerical). To help get you started, I've set up a bit of the code so that your plot output won't be scrunched together.  All you need to do is add a line of code that makes the box plot and then do the following:\n",
    "\n",
    "1. Set the ax keyword argument in your boxplot function to be the name of the axis I've created below\n",
    "2. Turn off the grid\n",
    "3. Set the x-axis label rotation to be 45˚ \n",
    "4. Add a y-axis label\n",
    "5. Add a title (but first get rid of the default suptitle by setting the suptitle of the plot to an empty string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15,4))\n",
    "###YOUR BOX PLOT CODE HERE####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.4.2 Do all years have the same median sampling month?\n",
    "Do the annual data generally agree with the histogram in Q3.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.5 Make a set of histograms based on density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.5.1\n",
    "In oceanography, it is often instructive to look at data on density surfaces rather than by depth. In this question, you'll make a 1x3 set of subplots consisting of histograms for the variables theta, oxygen, and cfc-11, binned by potential density (sigma0). In other words, you'll be making summary plots showing the total number of samples of these variables that fall within specific density ranges. \n",
    "\n",
    "You'll need to do the following:\n",
    "\n",
    "1. Group your theta, oxygen, and cfc-11 data by potential density (sigma0). Use the following array as your density bin edges: \n",
    "`bin_edges=np.arange(19.9,28.2,0.2)`\n",
    "><b><font color='green'>Hint</font></b>: Take a look at [cut()](https://pandas.pydata.org/docs/reference/api/pandas.cut.html) \n",
    "2. Make a set of counts for each variable based on the density bins\n",
    "3. Use [matplotlib bar graphs](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html) to make the 1x3 set of plots. Be sure to include axes labels, titles, etc. Change the color and edgecolor of the bars and set the bar width to be the width of a single density bin.\n",
    "><b><font color='red'>Note:</font></b> To make these plots properly with a bar graph, you will need to compute the bin centers from the bin edges and plot your counts vs your bin centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.5.2 What density bin contains the largest number of samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3.5.3 Understanding plt.hist() vs plt.bar()\n",
    "Look up the documentation for matplotlib's `hist()` function. Given the inputs of this function, why do you suppose we couldn't just feed our output from Q3.5.1 into it in order to make the histograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:uw-fall-2024]",
   "language": "python",
   "name": "conda-env-uw-fall-2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=20, color='#A020F0'>Homework 2</font></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this homework you'll further explore pandas by working with oceanographic research cruise data from the Arctic\n",
    "\n",
    "<b><font color='red'>Due Date: 10 October 2022</font></b><br>(by the beginning of class)\n",
    "\n",
    "<b>How you will turn in this assignment</b><br> When you are ready to turn in your homework, do the following steps:\n",
    "1. Execute all cells in your notebook so that the results are visible, and save one more time. It is ok if you have code that you practiced with, but <b><u>make sure your final answers to each question are clearly marked so that your TA and I know what to grade</u></b>. (You can also collapse the code and outputs that you _don't_ want us to grade; options to collapse and expand code are in the 'View' menu in the upper left)\n",
    "2. Open a terminal and navigate to your local `aos573_completed_assignments` repository and make a new directory called `completed_HW2`\n",
    "3. Move your completed jupyter notebook into this directory\n",
    "4. `add` and `commit` the `completed_HW2` directory and its contents to your local `aos573_completed_assignments` repository\n",
    "5. Finally, `push` your changes to your remote `aos573_completed_assignments` repository: `git push finished_work main` (you'll need to enter your username and personal access token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Getting the data and summarizing it\n",
    "The data we'll be using for this homework is from the [Global Ocean Data Analysis Project (GLODAP)](https://www.glodap.info/), which is a massive, global synthesis of quality-controlled ocean biogeochemical observations. GLODAP contains data from thousands of cruises from the early 1970s to the present. Here we'll only work with data from the Arctic Ocean.\n",
    "\n",
    "Run the following commands to download and unzip the GLODAP Arctic Ocean data:\n",
    "```bash\n",
    "!curl -O https://www.glodap.info/glodap_files/v2.2021/GLODAPv2.2021_Arctic_Ocean.csv.zip\n",
    "!unzip GLODAPv2.2021_Arctic_Ocean.csv.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has far more variables than you'll be working with in this assigment, so to help you out, below I've given you the code to read in only a subset of the variables, and I've renamed the columns slightly. If you want to compare what I've done here to the unsubsetted dataset, feel free to read the entire thing in on your own with `pandas.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of variables \n",
    "names=['station','year','month','day','hour','minute','latitude','longitude','depth','theta','salinity',\n",
    "                      'salinityf','sigma0','oxygen','oxygenf','cfc11','cfc11f']\n",
    "#Read in only the variables above with `usecols`\n",
    "df=pd.read_csv('GLODAPv2.2021_Arctic_Ocean.csv',sep=',',usecols=['G2'+i for i in names])\n",
    "#Reset the column names to be those in the list above and not the original names, \n",
    "#which all have 'G2' appended to the front\n",
    "df.columns=names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dataset info that you will find helpful (or access the entirety of the [metadata](https://www.ncei.noaa.gov/data/oceans/ncei/ocads/metadata/0237935.html) if you would like):\n",
    "\n",
    "1. year, month, day, hour, minute = sampling date and time\n",
    "2. latitude/longitude = geographical coordinates of the sampling location\n",
    "3. depth (m) = the depth of the water sample in meters\n",
    "4. missing fill value = -9999.0 (the fill value used when data is missing)\n",
    "\n",
    "Here is a list of the remaining variables, their descriptions, and their units:\n",
    "\n",
    "| Variable | Description | Unit | \n",
    "| - | - | - |\n",
    "| theta | potential temperature | $^\\circ$C |\n",
    "| salinity | salinity on the practical salinity scale | none |\n",
    "| salinityf | salinity flag; 0 = interpolated, 2 = good data, 9 = missing data | none |\n",
    "| sigma0 | potential density referenced to the ocean surface | kg m$^{-3}$ |\n",
    "| oxygen | oxygen content | $\\mu$mol kg$^{-1}$ |\n",
    "| oxygenf | oxygen flag; 0 = interpolated, 2 = good data, 9 = missing data | none |\n",
    "| cfc-11 | chlorofluorcarbon-11 content | pmol kg$^{-1}$ |\n",
    "| cfc-11f | cfc-11 flag; 2 = good data, 9 = missing data | none |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1 Get some basic information about your dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1.1 Print the summary information about your dataframe. \n",
    "1. How many samples are there for any given variable?\n",
    "2. How many different datatypes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.1.2 Print the summary statistics for your dataframe\n",
    "1. What is the range of latitude and longitude that the dataset covers?\n",
    "2. What is the mean potential temperature? Does this seem reasonable? What do you think is the cause?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Replacing missing values\n",
    "Use [where()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.where.html) to replace all of the missing values with NaNs. Rerun your summary statistics from Q1.1.2. What is the mean potential temperature now? For this question, please print _only_ the new mean value of potential temperature, and not the entire summary statistics table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3 A quick look at the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.3.1 Show the last 8 values of the dataset. \n",
    "This is the data collected at one stop (a 'station') on one reasearch cruise. You can tell this because the lat/lon values don't change, nor does the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.3.2 For which variables were data not collected at this station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1.3.3 Over what depth range were water samples collected at this station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Working with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1.1 Make a very quick line plot of the years in the dataset\n",
    "Use pandas built-in plotting and don't bother making any adjustments to the output. What does the plot tell you about how the years are arranged in your dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1.2 Sort your dataframe so that the years are increasing\n",
    "Use your sorted dataframe for the rest of the assigment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2.1 How many samples were taken above and below 500 m?\n",
    "Base your answer off of depth, not one of the other variables like salinity, etc, as some of those will have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2.2 How many salinity, oxygen, and CFC-11 samples in the entire dataset were interpolated?\n",
    "Provide your answers as percentages of the total number of samples for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2.3 Between 1980 and 1990, how many oxygen samples were taken north of 80˚N?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2.4 How many distinct locations in the Arctic were sampled?\n",
    "In this question, I want you to find the total number of _unique_ lat/lon _pairs_. <b> Hint:</b> Take a look at [drop_duplicates()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2.5 In what years were the largest and smallest number of samples taken?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.2.6 In how many years were data collected?\n",
    "How does this compare to the total number of years that the dataset spans?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3 Make a histogram of the number of samples in each month \n",
    "For this problem, you'll need to create a new dataframe using `drop_duplicates()`.  Because the number of sample depths varies per station, if we make a histogram based solely on the 'months' column, we'll skew our results based on the number of depths sampled at a given station. To avoid counting mulitple samples across depth at the same station, what we truly want is the unique _date_ and _time_ that sampling occurred at a particular station, so you should make your histogram based on your new dataframe that ignores duplicate entries for the date and time.\n",
    "\n",
    "No need to bother making your plot look pretty for this question--as long as you can answer the questions below then it's fine (but do make sure that your plot has one bin per month)!\n",
    "\n",
    "1. In what month were the largest number of samples taken?\n",
    "2. In what month were the smallest number of samples taken?\n",
    "3. Pretend like the data you plotted on your histogram is the data you have for one year. If you took the annual mean of your data, how might you expect your results to be biased (i.e. toward what season would your annual mean skew)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.4 Visualizing data with a box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.4.1 Make a box plot of the spread in number of samples across all months for each year\n",
    "Use your new dataframe from Q2.3. Your [box plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.boxplot.html) should have one box showing the spread in monthly sample numbers for each year. Your x-axis should be the years of the dataset and your y-axis should be the months (these should be numerical). To help get you started, I've set up a bit of the code so that your plot output won't be scrunched together.  All you need to do is add a line of code that makes the box plot and then do the following:\n",
    "\n",
    "1. Set the ax keyword argument in your boxplot function to be the name of the axis I've created below\n",
    "2. Turn off the grid\n",
    "3. Set the x-axis label rotation to be 45˚ \n",
    "4. Add a y-axis label\n",
    "5. Add a title (but first get rid of the default suptitle by setting the suptitle of the plot to an empty string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "fig.set_size_inches(15,4)\n",
    "###YOUR BOX PLOT CODE HERE####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.4.2 Do all years have the same median sampling month?\n",
    "Do the annual data generally agree with the histogram in Q2.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.5 Make a set of histograms based on density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.5.1\n",
    "In oceanography, it is often instructive to look at data on density surfaces rather than by depth. In this question, you'll make a 1x3 set of subplots consisting of histograms for the variables theta, oxygen, and cfc-11, binned by potential density (sigma0). In other words, you'll be making summary plots showing the total number of samples of these variables that fall within specific density ranges. \n",
    "\n",
    "You'll need to do the following:\n",
    "\n",
    "1. Group your theta, oxygen, and cfc-11 data by potential density (sigma0). Use the following array as your density bin edges: \n",
    "`bin_edges=np.arange(19.9,28.2,0.2)\n",
    "` <b>Hint</b>: Take a look at [cut()](https://pandas.pydata.org/docs/reference/api/pandas.cut.html) \n",
    "2. Make a set of counts for each variable based on the density bins\n",
    "3. Use [matplotlib bar graphs](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.bar.html) to make the 1x3 set of plots. Be sure to include axes labels, titles, etc. Change the color and edgecolor of the bars and set the bar width to be the width of a single density bin. <b>Note:</b> To make these plots properly with a bar graph, you will need to compute the bin centers from the bin edges and plot your counts vs your bin centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.5.2 What density bin contains the largest number of samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.5.3 Understanding plt.hist() vs plt.bar()\n",
    "Look up the documentation for matplotlib's `hist()` function. Given the inputs of this function, why do you suppose we couldn't just feed our output from Q2.5.1 into it in order to make the histograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
